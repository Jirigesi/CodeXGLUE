{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fjiriges/anaconda3/envs/cuBERT/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import json\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_tokens,\n",
    "                 input_ids,\n",
    "                 idx,\n",
    "                 label,\n",
    "\n",
    "    ):\n",
    "        self.input_tokens = input_tokens\n",
    "        self.input_ids = input_ids\n",
    "        self.idx=str(idx)\n",
    "        self.label=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(js,tokenizer,args):\n",
    "    #source\n",
    "    code=' '.join(js['func'].split())\n",
    "    code_tokens=tokenizer.tokenize(code)[:args.block_size-2]\n",
    "    source_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "    source_ids =  tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    padding_length = args.block_size - len(source_ids)\n",
    "    source_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "    \n",
    "    return InputFeatures(source_tokens,source_ids,js['idx'],js['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, args, file_path=None):\n",
    "        self.examples = []\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                js=json.loads(line.strip())\n",
    "                self.examples.append(convert_examples_to_features(js,tokenizer,args))\n",
    "        if 'train' in file_path:\n",
    "            for idx, example in enumerate(self.examples[:3]):\n",
    "                    logger.info(\"*** Example ***\")\n",
    "                    logger.info(\"idx: {}\".format(idx))\n",
    "                    logger.info(\"label: {}\".format(example.label))\n",
    "                    logger.info(\"input_tokens: {}\".format([x.replace('\\u0120','_') for x in example.input_tokens]))\n",
    "                    logger.info(\"input_ids: {}\".format(' '.join(map(str, example.input_ids))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):       \n",
    "        return torch.tensor(self.examples[i].input_ids),torch.tensor(self.examples[i].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer,eval_when_training=False):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    eval_dataset = TextDataset(tokenizer, args,args.eval_data_file)\n",
    "\n",
    "    if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size,num_workers=4,pin_memory=True)\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1 and eval_when_training is False:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "    logits=[] \n",
    "    labels=[]\n",
    "    for batch in eval_dataloader:\n",
    "        inputs = batch[0].to(args.device)        \n",
    "        label=batch[1].to(args.device) \n",
    "        with torch.no_grad():\n",
    "            lm_loss,logit = model(inputs,label)\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "            logits.append(logit.cpu().numpy())\n",
    "            labels.append(label.cpu().numpy())\n",
    "        nb_eval_steps += 1\n",
    "    logits=np.concatenate(logits,0)\n",
    "    labels=np.concatenate(labels,0)\n",
    "    preds=logits[:,0]>0.5\n",
    "    eval_acc=np.mean(labels==preds)\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    perplexity = torch.tensor(eval_loss)\n",
    "            \n",
    "    result = {\n",
    "        \"eval_loss\": float(perplexity),\n",
    "        \"eval_acc\":round(eval_acc,4),\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuBERT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8492d8711f92acbd6f1f5de70669e0e0dfa9ae8288673c2cd77f66771fab39c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
